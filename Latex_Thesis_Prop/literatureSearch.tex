 
\section{Literature Search}
Background literature for this masters thesis spans several fields related to phonetics and phonology and provides motivation for the development of the proposed CAPT tool. The first subsection covers second language learning research which provides theories on why certain speech sounds are persistently misclassified by second language learners. This research is also used to identify some pedagogic goals for learning new phonetic categories in order to overcome these errors.  The next sub-section covers research in describing and measuring the vowel space.  This research will be put to use in creating algorithms for the CAPT system which measure users' vowel spaces and calculate what acoustic targets they should move towards for improved German Pronunciation.   The third literature sub-section will look at existing CAPT systems to provide examples of successful and unsuccessful feedback strategies which will inform the development of the interface for the proposed tool.



\subsection{Second Language Learning}
Research in second language learning has shown that adult learners of a foreign language experience persistent difficulty in perceiving certain phonological contrasts due to interference from the phonology of their native language. For vowel contrasts, studies performed across several language pairs point to difficulties in perception when the learners' native language has a single vowel category in a given acoustic region, and the target language has two or more vowel categories in a similar region \citep{pallier1997limit,flege1999native}. Difficulty also arises for vowel categories which are contrastive in duration \textit{and} spectral values \cite{weber2014treack}. A study of French speakers learning Germany by Zimmerer and Trouvain \citep{zimmerer pending publication} posits that these perceptional difficulties carry over into production, where French speakers often failed to correctly produce short vowels because French phonology lacks a long-short vowel contrast.  Research from Flege \cite{flege1995second} proposes a model to account for these phenomena, which hypothesizes that the formation of a new category for an L2 sound may be blocked and falsely classified as equivalent to a category in the L1 if the sounds are similar and learners lack the ability to perceive the acoustic or phonetic features which distinguish between the two. The model goes on to state that the production of the L2 sound will resemble that of the L1 category to which it was assimilated. 
\\
\\
The model by Flege also provides hypotheses as to how new vowel categories can be successfully created. If bilingual learners are able to discern at least some of the features (such as spectral values or vowel duration) that differentiate a sound in the L2 with a vowel category in the L1, they may successfully form a new category. However, the establishment of a new vowel category for bilingual learners may rely on different features or feature weights to define the category boundaries as compared to a native speaker. Experimental evidence of this has been show in the perception of Dutch vowels by Spanish and German learners of Dutch \cite{escudero2009native}. For example, Spanish learners of Dutch rely heavily on vowel duration to categorize tokens of /\textipa{a-A}/, while L1 German learners and L1 Dutch natives rely more heavily on spectral information. The implication of the research presented in the section suggests that while the phenomena of vowel category misclassification is widespread among L2 learners, errors are specific to the learners L1 background, and strategies for overcoming these errors may also need to be language specific. From these findings the following priorities are established for assisting L2 learners with vowel perception and production:  Firstly, learners should be aware of the features which differentiate similar sound in the target language, such as the duration and spectral values. These features may also be described by their physical correlates, for instance tongue/jaw position (F1 \& F2 spectral information) or lip rounding (F3 spectral information).  Secondly, all relevant features which can help determine vowel boundaries should be presented to the learner.  And Finally, features which carry the most weight in determining boundaries (for a specific L1 to L2 language pair) should be highlighted to focus the learners attention on the most productive differences. 

\subsection{Defining the Vowel Space}
 \textbf{Write 2 paragraphs just covering the basics of how the vowel space can be measured, and then provide a few sentences at the end of the second paragraph about how this type of research can be helpful in determining the appropriate acoustic targets for L2 learners trying to produce German vowels.}
 \\
Literature on defining and measuring the vowels and the vowel space will be put to use in designing the algorithms which give the CAPT tool it's functionality. It must be noted that one of the largest challenges of providing useful feedback about vowels is that the vowel space for any given language is highly variable between speakers, and also dependent upon the phonetic and prosodic context \citep{Jongman, Gendrot}. This has several implications for designing a CAPT system: For the base case of feedback, one must describe vowel category targets as regions, rather than exact values.  For a more advanced system, the regions describing vowel categories can be refined based on the specific resonance profile of the user's vocal tract and the context in which vowels are being produced.

\subsection{Computer Assisted Pronunciation Training}
The final section of background literature covers CAPT systems, which offer various exercises and levels of feedback aimed  at improving L2 learners' pronunciation. The automatization offered by CAPT technology is a promising field for language education, because it may allow students to practice pronunciation without the need for a language instructor. It can also be a powerful tool in addressing issues with foreign accent which may be difficult or even impossible to isolate in a typical classroom setting \cite{thomson2011computer}. However, there is a great deal of discussion about what parts of the signal are amenable to searching for pronunciation errors (e.g. segment, word, phrase) and once that information is gathered, what are the best methods of providing feedback \cite{hansen2006computer,neri2002pedagogy}.  Therefore, for the development of the proposed CAPT tool, looking at previous CAPT systems can be useful in determining what to measure, and developing some guidelines for pedagogically sound feedback.
\\
\\
For most L2 learners, any previous contact with a CAPT tool probably came from using a commercial product such as Rosetta Stone or Duolingo which employ some sort of Automatic Speech Recgonition (ASR) to rate the quality of sentences produced by users. These systems have been regarded as problematic by the academic community because they typically only provide a single rating on the quality of pronunciation throughout a whole sentence \citep{thomson2011computer}. This makes little pedagogic sense because the feedback is very coarse grained and the learner cannot use that information to improve the production of any specific sounds or the overall prosody of the phrase \cite{hansen2006computer}. In addition the speech recognition algorithm used for evaluating the accent is completely opaque, and therefore it is unclear what qualities constitute a normal accent, and what qualities are considered foreign. The shortcoming of these commercial systems provide a good example of mistakes to avoid, and show the need for explicit feedback for pronunciation errors rather than an implicit good/bad rating system.
\\
\\
Fortunately there are CAPT systems which provide more explicit feedback and are sufficiently descriptive so that users identify their errors and act to correct them. For example, there are several CAPT systems which produce some visual analogy of the speech signal (or parts thereof) and encourage the user to aim for a certain pronunciation target\cite{neri2002pedagogy}. Some early systems provided the user with an oscillogram and spectrogram of their speech production which could be compared to some gold standard. The clear drawback of this type of feedback is that it is very difficult to interpret, and requires prior phonetics training to read the oscillogram and spectrogram \cite{hansen2006computer}. More success has been found in displaying abstract visual feedback derived from the speech signal. For instance a system which display representations of intonation, stress, and rhythm as visual cues to improve pronunciation of suprasegmentals in an L2 language \cite{kommissarchik2000better}, or a system which is designed to correct segment level errors by providing a visual representation of the vocal tract moving with the speech signal \cite{wong2011allophonic}. CAPT tools such these show how automatic signal processing and visualization techniques can provide useful analogies of a speaker's voice which would be impossible in a typical classroom setting. This type of signal measurement and feedback will serve as a useful template for the development of the proposed CAPT tool for this Masters Thesis.


